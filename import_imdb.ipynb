{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸ¬ Analyse IMDb - PrÃ©paration des donnÃ©es\n",
    "\n",
    "**Objectif** : CrÃ©er un dataset propre avec films, notes, genres et acteurs/rÃ©alisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_paths",
   "metadata": {},
   "source": [
    "## ğŸ“ Configuration des chemins (relatifs pour GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins relatifs (compatible GitHub)\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PARQUET_DIR = DATA_DIR / \"PARQUETS\"\n",
    "\n",
    "# CrÃ©er les dossiers\n",
    "PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Dossier crÃ©Ã© : {PARQUET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Ã‰TAPE 1 : Charger et filtrer title.basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL IMDb\n",
    "url_basics = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "\n",
    "# Chemin de sauvegarde\n",
    "parquet_basics = PARQUET_DIR / \"title_basics_movies.parquet\"\n",
    "\n",
    "# ParamÃ¨tres\n",
    "chunk_size = 500_000\n",
    "colonnes_utiles = [\n",
    "    'tconst', 'titleType', 'primaryTitle', 'originalTitle',\n",
    "    'isAdult', 'startYear', 'runtimeMinutes', 'genres'\n",
    "]\n",
    "\n",
    "# Lecture par chunks\n",
    "chunks_filtres = []\n",
    "print(\"ğŸ”„ Traitement de title.basics...\")\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\n",
    "    url_basics,\n",
    "    sep='\\t',\n",
    "    chunksize=chunk_size,\n",
    "    usecols=colonnes_utiles,\n",
    "    dtype={'startYear': str, 'runtimeMinutes': str},\n",
    "    na_values='\\\\N'\n",
    "), 1):\n",
    "    \n",
    "    # âœ… FILTRES COMPLETS\n",
    "    chunk_filtre = chunk[\n",
    "        (chunk['titleType'] == 'movie') &\n",
    "        (chunk['isAdult'] == '0') &  # â† IMPORTANT : Exclure films adultes\n",
    "        (chunk['startYear'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    # Conversions\n",
    "    chunk_filtre['startYear'] = pd.to_numeric(chunk_filtre['startYear'], errors='coerce')\n",
    "    chunk_filtre['runtimeMinutes'] = pd.to_numeric(chunk_filtre['runtimeMinutes'], errors='coerce')\n",
    "    \n",
    "    # Filtre sur les annÃ©es (aprÃ¨s 1970)\n",
    "    chunk_filtre = chunk_filtre[chunk_filtre['startYear'] > 1970]\n",
    "    \n",
    "    chunks_filtres.append(chunk_filtre)\n",
    "    print(f\"  Chunk {i} : {len(chunk_filtre):,} films gardÃ©s\")\n",
    "\n",
    "# ConcatÃ©nation\n",
    "df_movies = pd.concat(chunks_filtres, ignore_index=True)\n",
    "print(f\"\\nâœ… Total : {len(df_movies):,} films conservÃ©s\")\n",
    "print(f\"ğŸ“Š PÃ©riode : {df_movies['startYear'].min():.0f} - {df_movies['startYear'].max():.0f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "df_movies.to_parquet(parquet_basics, engine='pyarrow', compression='snappy', index=False)\n",
    "print(f\"ğŸ’¾ SauvegardÃ© : {parquet_basics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Ã‰TAPE 2 : Charger title.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL IMDb\n",
    "url_ratings = \"https://datasets.imdbws.com/title.ratings.tsv.gz\"\n",
    "parquet_ratings = PARQUET_DIR / \"title_ratings.parquet\"\n",
    "\n",
    "print(\"ğŸ”„ Traitement de title.ratings...\")\n",
    "\n",
    "# Lecture\n",
    "df_ratings = pd.read_csv(url_ratings, sep='\\t', na_values='\\\\N')\n",
    "\n",
    "# Filtrer pour garder seulement nos films\n",
    "tconst_movies = set(df_movies['tconst'])\n",
    "df_ratings = df_ratings[df_ratings['tconst'].isin(tconst_movies)]\n",
    "\n",
    "print(f\"âœ… {len(df_ratings):,} ratings conservÃ©s\")\n",
    "\n",
    "# Sauvegarde\n",
    "df_ratings.to_parquet(parquet_ratings, engine='pyarrow', compression='snappy', index=False)\n",
    "print(f\"ğŸ’¾ SauvegardÃ© : {parquet_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "## ğŸ”— Ã‰TAPE 3 : CrÃ©er le dataset complet avec genres encodÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure movies + ratings\n",
    "print(\"ğŸ”— Jointure movies + ratings...\")\n",
    "df_complet = df_movies.merge(df_ratings, on='tconst', how='left')\n",
    "\n",
    "print(f\"âœ… Dataset complet : {len(df_complet):,} films\")\n",
    "print(f\"ğŸ“Š Films avec notes : {df_complet['averageRating'].notna().sum():,}\")\n",
    "\n",
    "# Encoder les genres\n",
    "print(\"\\nğŸ­ Encodage des genres...\")\n",
    "df_complet['genres'] = df_complet['genres'].fillna('')\n",
    "df_complet = pd.concat([\n",
    "    df_complet,\n",
    "    df_complet['genres'].str.get_dummies(sep=',')\n",
    "], axis=1)\n",
    "\n",
    "genre_cols = [col for col in df_complet.columns if col not in df_movies.columns and col not in df_ratings.columns]\n",
    "print(f\"âœ… {len(genre_cols)} genres encodÃ©s\")\n",
    "\n",
    "# AperÃ§u\n",
    "print(\"\\nğŸ” AperÃ§u :\")\n",
    "display(df_complet.head())\n",
    "\n",
    "# Sauvegarde intermÃ©diaire\n",
    "parquet_complet = PARQUET_DIR / \"imdb_complet_base.parquet\"\n",
    "df_complet.to_parquet(parquet_complet, engine='pyarrow', compression='snappy', index=False)\n",
    "print(f\"ğŸ’¾ SauvegardÃ© : {parquet_complet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "## ğŸ­ Ã‰TAPE 4 : Ajouter les acteurs et rÃ©alisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_principals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL IMDb\n",
    "url_principals = \"https://datasets.imdbws.com/title.principals.tsv.gz\"\n",
    "\n",
    "# ParamÃ¨tres\n",
    "chunks_filtres = []\n",
    "chunk_size = 500_000\n",
    "\n",
    "print(\"ğŸ”„ Traitement de title.principals (peut prendre 10 min)...\")\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\n",
    "    url_principals,\n",
    "    sep='\\t',\n",
    "    chunksize=chunk_size,\n",
    "    usecols=['tconst', 'ordering', 'nconst', 'category'],\n",
    "    na_values='\\\\N'\n",
    "), 1):\n",
    "    \n",
    "    # Filtre : Top 5 acteurs + tous les rÃ©alisateurs\n",
    "    chunk_filtre = chunk[\n",
    "        (chunk['tconst'].isin(tconst_movies)) &\n",
    "        (\n",
    "            ((chunk['category'].isin(['actor', 'actress'])) & (chunk['ordering'] <= 5)) |\n",
    "            (chunk['category'] == 'director')\n",
    "        )\n",
    "    ].copy()\n",
    "    \n",
    "    chunks_filtres.append(chunk_filtre)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"  {i} chunks traitÃ©s\")\n",
    "\n",
    "df_principals = pd.concat(chunks_filtres, ignore_index=True)\n",
    "print(f\"\\nâœ… {len(df_principals):,} lignes conservÃ©es\")\n",
    "\n",
    "# Sauvegarder\n",
    "parquet_principals = PARQUET_DIR / \"title_principals_filtered.parquet\"\n",
    "df_principals.to_parquet(parquet_principals, engine='pyarrow', compression='snappy', index=False)\n",
    "print(f\"ğŸ’¾ SauvegardÃ© : {parquet_principals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les noms\n",
    "url_names = \"https://datasets.imdbws.com/name.basics.tsv.gz\"\n",
    "nconst_needed = set(df_principals['nconst'])\n",
    "\n",
    "print(\"ğŸ”„ Chargement des noms...\")\n",
    "chunks_names = []\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\n",
    "    url_names,\n",
    "    sep='\\t',\n",
    "    chunksize=500_000,\n",
    "    usecols=['nconst', 'primaryName'],\n",
    "    na_values='\\\\N'\n",
    "), 1):\n",
    "    chunks_names.append(chunk[chunk['nconst'].isin(nconst_needed)])\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  {i} chunks traitÃ©s\")\n",
    "\n",
    "df_names = pd.concat(chunks_names, ignore_index=True)\n",
    "print(f\"âœ… {len(df_names):,} noms rÃ©cupÃ©rÃ©s\")\n",
    "\n",
    "# Sauvegarder\n",
    "parquet_names = PARQUET_DIR / \"name_basics_filtered.parquet\"\n",
    "df_names.to_parquet(parquet_names, engine='pyarrow', compression='snappy', index=False)\n",
    "print(f\"ğŸ’¾ SauvegardÃ© : {parquet_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge_cast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joindre les noms\n",
    "print(\"ğŸ”— Jointure principals + names...\")\n",
    "df_principals_noms = df_principals.merge(df_names, on='nconst', how='left')\n",
    "\n",
    "# CrÃ©er les listes d'acteurs et rÃ©alisateurs par film\n",
    "acteurs = df_principals_noms[\n",
    "    df_principals_noms['category'].isin(['actor', 'actress'])\n",
    "].groupby('tconst')['primaryName'].apply(list).reset_index(name='acteurs')\n",
    "\n",
    "realisateurs = df_principals_noms[\n",
    "    df_principals_noms['category'] == 'director'\n",
    "].groupby('tconst')['primaryName'].apply(list).reset_index(name='realisateurs')\n",
    "\n",
    "print(f\"âœ… {len(acteurs):,} films avec acteurs\")\n",
    "print(f\"âœ… {len(realisateurs):,} films avec rÃ©alisateurs\")\n",
    "\n",
    "# Joindre Ã  df_complet\n",
    "df_complet = df_complet.merge(acteurs, on='tconst', how='left')\n",
    "df_complet = df_complet.merge(realisateurs, on='tconst', how='left')\n",
    "\n",
    "# Remplacer NaN par listes vides\n",
    "df_complet['acteurs'] = df_complet['acteurs'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df_complet['realisateurs'] = df_complet['realisateurs'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "print(f\"\\nâœ… Dataset final : {df_complet.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Ã‰TAPE 5 : Sauvegarde finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde finale\n",
    "parquet_final = PARQUET_DIR / \"imdb_complet_avec_cast.parquet\"\n",
    "df_complet.to_parquet(parquet_final, engine='pyarrow', compression='snappy', index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… TRAITEMENT TERMINÃ‰ !\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ’¾ Dataset final : {parquet_final}\")\n",
    "print(f\"ğŸ“Š Dimensions : {df_complet.shape}\")\n",
    "print(f\"\\nğŸ“‹ Statistiques :\")\n",
    "print(f\"  â€¢ Films : {len(df_complet):,}\")\n",
    "print(f\"  â€¢ Avec notes : {df_complet['averageRating'].notna().sum():,}\")\n",
    "print(f\"  â€¢ Avec acteurs : {df_complet['acteurs'].apply(len).gt(0).sum():,}\")\n",
    "print(f\"  â€¢ Avec rÃ©alisateurs : {df_complet['realisateurs'].apply(len).gt(0).sum():,}\")\n",
    "\n",
    "print(\"\\nğŸ” AperÃ§u final :\")\n",
    "display(df_complet[['primaryTitle', 'startYear', 'genres', 'averageRating', 'acteurs', 'realisateurs']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
